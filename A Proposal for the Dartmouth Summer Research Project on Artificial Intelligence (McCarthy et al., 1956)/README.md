# A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence

> **Quick Summary**: The founding document of AI as a formal field, proposing a 2-month workshop where the term "artificial intelligence" was first used and the foundational problems of the field were outlined.

---

## Paper Metadata

| Field | Value |
|-------|-------|
| **Title** | A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence |
| **Authors** | J. McCarthy, M. L. Minsky, N. Rochester, C.E. Shannon |
| **Affiliation(s)** | Dartmouth College, Harvard University, IBM Corporation, Bell Telephone Laboratories |
| **Publication Venue** | Research Proposal / Historical Document |
| **Year** | 1955 (dated August 31, 1955) |
| **Paper Link** | Available in various archives |
| **Field/Subfield** | Artificial Intelligence (Field-defining) |

---

## Core Contribution

### What Problem Does This Paper Solve?

Before this proposal, research on machine intelligence was scattered across different fields - cybernetics, information theory, neurology, and computing - with no unified framework or terminology. Researchers were working on related problems but lacked a common vocabulary and collaborative structure. There was no formal recognition of "artificial intelligence" as a distinct field of study. This proposal aimed to bring together leading minds to establish AI as a legitimate scientific discipline with clearly defined problems and methods.

### Key Innovations

1. **Conceptual Framework**: Introduced the term "artificial intelligence" and formally defined it as making machines behave in ways that would be called intelligent if a human were doing them
2. **Problem Decomposition**: Broke down the ambitious goal of machine intelligence into seven concrete, attackable subproblems
3. **Interdisciplinary Approach**: Brought together experts from mathematics, engineering, neurology, and information theory to attack the problem collaboratively

### Main Hypothesis/Claim

The central conjecture of this proposal is radical and foundational: "every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it." This is essentially a statement that intelligence is computational and can be mechanized - a hypothesis that remains at the heart of AI research today.

---

## Methodology

### Approach Overview

The proposal outlined a collaborative research methodology where 10 carefully selected scientists would work together for 2 months in summer 1956. Participants would share their previous work beforehand, then engage in regular seminars while also working individually and in informal small groups. The focus was on attacking specific subproblems of machine intelligence through both theoretical analysis and practical experimentation.

### Technical Details

#### Seven Core Problems Identified

The proposal identified seven distinct aspects of artificial intelligence to study:

1. **Automatic Computers**: Recognizing that the bottleneck wasn't machine capacity but our ability to write programs that fully utilize available computing power

2. **Language Use**: How to program computers to manipulate words according to rules of reasoning and conjecture, forming generalizations by introducing new words and inference rules

3. **Neuron Nets**: How to arrange hypothetical neurons to form concepts, building on work by Uttley, Rashevsky, Pitts and McCulloch, and others

4. **Theory of Calculation Size**: Developing measures of computational efficiency and complexity to exclude brute-force approaches

5. **Self-Improvement**: Studying how machines could carry out activities that improve their own capabilities

6. **Abstractions**: Classifying types of abstraction and describing methods for machines to form abstractions from sensory and other data

7. **Randomness and Creativity**: Exploring whether the difference between creative and unimaginative thinking lies in controlled injection of randomness

#### Key Components

1. **Shannon's Focus**: Information theory applied to computing machines and brain models, studying reliable computing with unreliable elements and information networks with closed loops

2. **Minsky's Approach**: Building machines that develop both sensory and motor abstractions, creating internal models of their environment to enable "imaginative" behavior through internal simulation before external action

3. **Rochester's Vision**: Achieving machine originality through appropriate introduction of randomness, guided by the brain's approach to handling uncertainty and novel problems

4. **McCarthy's Goal**: Developing a formal language that computers could use for conjecture and self-reference, with properties similar to English for handling complex phenomena

---

## Key Insights & Takeaways

### What Makes This Work?

The brilliance of this proposal lies in several key insights:

1. **Decomposition Strategy**: Instead of tackling "intelligence" as a monolithic problem, the authors broke it into manageable subproblems that could be studied independently

2. **Balance of Theory and Practice**: The proposal recognized that both abstract theoretical work and concrete implementation were necessary

3. **Cross-Pollination**: By bringing together experts from different fields, the workshop could leverage diverse perspectives on the same fundamental problems

4. **Realism About Challenges**: The authors acknowledged that even with adequate machine capacity, the real obstacle was our limited understanding of how to program intelligence

### Surprising Findings

Several aspects of this 1955 proposal are remarkably prescient:

- Recognition that machine capacity wasn't the limiting factor - it was programming knowledge (still true today in many ways)
- The emphasis on language and abstraction as central to intelligence
- Understanding that self-improvement would be a key feature of truly intelligent systems
- The idea that creativity might involve controlled randomness
- Focus on learning from environment and building internal world models

### Limitations Acknowledged

The authors were admirably honest about uncertainties:

1. They acknowledged that their approaches were "conjectures" and "partially worked out" rather than proven methods
2. Rochester noted the difficulty of connecting neuron net behavior to actual problem-solving
3. They recognized that even with randomness, preventing chaos in machine behavior required foresight they didn't yet have
4. McCarthy admitted the formal languages of the time lacked key properties of natural language

---

## Strengths

1. **Visionary Scope**: This proposal essentially predicted and outlined what would become the central problems of AI for the next 70 years - natural language processing, learning, knowledge representation, planning, etc.

2. **Interdisciplinary Foundation**: By bringing together information theory (Shannon), neurological modeling (Minsky), practical computing (Rochester), and formal systems (McCarthy), the proposal established AI as inherently interdisciplinary

3. **Intellectual Honesty**: The authors didn't oversell their ideas. They presented conjectures, acknowledged uncertainties, and proposed research rather than claiming solved problems

4. **Concrete Problems**: Rather than vague philosophizing about "thinking machines," they identified specific technical challenges that could be researched systematically

5. **Balance of Approaches**: The proposal included both top-down approaches (formal languages, logic) and bottom-up approaches (neural nets, learning from environment)

---

## Weaknesses & Criticisms

### My Critical Analysis

1. **Extreme Optimism About Timeline**: The proposal suggested "a significant advance can be made in one or more of these problems" in just two months. In reality, these problems would take decades. This reflects a common pattern in AI of underestimating difficulty.

2. **Vague Success Metrics**: The proposal doesn't define what would constitute success or progress. How would they know if they made a "significant advance"? What would a solution to these problems look like?

3. **Limited Discussion of Knowledge**: While the proposal mentions abstractions and concepts, it underestimates the challenge of knowledge representation and the sheer amount of common-sense knowledge humans possess.

4. **Insufficient Attention to Data**: The proposal focuses heavily on algorithms and architectures but doesn't discuss the role of training data or experience in developing intelligence - something we now know is crucial.

5. **Neural Nets vs. Symbolic AI**: The proposal treats neural nets and symbolic reasoning as compatible approaches without recognizing they would lead to competing paradigms that wouldn't be unified for decades.

### Known Criticisms from Community

Over the years, critics have noted:

- The 1956 workshop didn't lead to immediate breakthroughs, and AI went through multiple "winters" when progress stalled
- The symbolic AI approach that dominated early work struggled with real-world complexity
- Many problems outlined in 1955 (natural language, vision, common sense) proved far harder than expected
- The field suffered from cycles of hype and disappointment partly due to early optimistic predictions

---

## Personal Insights

### Why This Paper Matters

This isn't just a historical curiosity - it's the birth certificate of an entire field. Reading this proposal in 2025, what strikes me most is:

1. How **accurate** the problem decomposition was - we're still working on these same seven problems
2. How **optimistic** the timeline was - two months to make significant progress on problems that have consumed 70 years
3. How **modern** some ideas sound - self-improvement, environment models, abstraction learning
4. How **different** the context was - they were working with computers that had kilobytes of memory

The proposal also reveals the personalities and approaches of four giants: Shannon's information-theoretic precision, Minsky's focus on modeling and abstraction, Rochester's engineering pragmatism, and McCarthy's logical formalism. Each of these approaches would spawn entire subfields of AI.

### Interesting Observations

1. **The Language Gap**: McCarthy's focus on language and formal systems would lead to logic programming and expert systems, while Minsky's neural nets would eventually evolve into deep learning. The tension between these approaches shaped AI's history.

2. **Randomness as Creativity**: Rochester's idea that creativity involves controlled randomness prefigures modern techniques like Monte Carlo methods, genetic algorithms, and even the sampling strategies in generative AI.

3. **Internal World Models**: Minsky's proposal that machines should build "internal abstract models of the environment" for planning is essentially what we now call model-based reinforcement learning.

4. **Self-Reference**: McCarthy's emphasis on self-reference and meta-reasoning anticipated meta-learning and AI systems that reason about their own reasoning.

5. **The Funding Request**: They asked for $13,500 (about $150,000 in 2025 dollars) - a tiny fraction of what modern AI research costs. Yet this small investment helped birth a field that would eventually be worth trillions.

### Questions for Further Exploration

1. Why did the symbolic AI approach dominate for so long when neural networks were part of the original vision?
2. How much progress have we actually made on the "core" problems versus just throwing more compute at statistical pattern matching?
3. What problems from this 1955 list remain fundamentally unsolved despite 70 years of work?
4. Did the interdisciplinary nature of early AI get lost as the field matured and specialized?
5. If McCarthy, Minsky, Shannon and Rochester could see 2025 AI, what would surprise them most? What would disappoint them?
6. Are there problems that should have been on this list but weren't, revealing blind spots in the original conception of AI?

---

## Tags

`ai-history` `foundational-document` `symbolic-ai` `neural-networks` `machine-learning` `1955` `dartmouth` `mccarthy` `minsky` `shannon` `rochester` `field-defining`

---

## Citation

```bibtex
@techreport{mccarthy1955proposal,
  title={A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence},
  author={McCarthy, John and Minsky, Marvin L and Rochester, Nathaniel and Shannon, Claude E},
  year={1955},
  month={August},
  institution={Dartmouth College}
}
```